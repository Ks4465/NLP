{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing in Natural Language Processing (NLP)\n",
    "\n",
    "Text preprocessing is a crucial step in preparing raw text data for analysis and modeling in Natural Language Processing (NLP). This process involves several techniques to clean and transform the text into a format that can be effectively used by machine learning algorithms.\n",
    "\n",
    "## Steps of Text Preprocessing\n",
    "\n",
    "### 1. **Tokenization**\n",
    "   - **Definition**: The process of breaking down text into smaller units called tokens, which can be words, phrases, or sentences.\n",
    "   - **Purpose**: Tokenization allows us to analyze text at a granular level.\n",
    "\n",
    "### 2. **Lowercasing**\n",
    "   - **Definition**: Converting all characters in the text to lowercase.\n",
    "   - **Purpose**: Helps in reducing the complexity of the data by treating words like \"Apple\" and \"apple\" as the same token.\n",
    "\n",
    "### 3. **Stopword Removal**\n",
    "   - **Definition**: The removal of common words (stopwords) that do not add significant meaning to the text, such as \"is\", \"the\", \"and\".\n",
    "   - **Purpose**: Reduces the noise in the text, allowing the model to focus on more informative words.\n",
    "\n",
    "### 4. **Stemming**\n",
    "   - **Definition**: The process of reducing words to their root form by removing suffixes and prefixes. For example, \"running\" becomes \"run\".\n",
    "   - **Purpose**: Helps in reducing inflected words to their base form, thus consolidating similar words.\n",
    "\n",
    "### 5. **Lemmatization**\n",
    "   - **Definition**: Similar to stemming, but lemmatization considers the context and meaning of the word, converting it to its base or dictionary form. For example, \"better\" becomes \"good\".\n",
    "   - **Purpose**: Provides a more accurate representation of the word by understanding its meaning and usage.\n",
    "\n",
    "### 6. **Part-of-Speech (POS) Tagging**\n",
    "   - **Definition**: The process of assigning grammatical categories (such as noun, verb, adjective) to each word in a sentence.\n",
    "   - **Purpose**: Helps in understanding the grammatical structure and meaning of sentences.\n",
    "\n",
    "### 7. **Named Entity Recognition (NER)**\n",
    "   - **Definition**: The identification and classification of named entities in the text (such as names of people, organizations, and locations).\n",
    "   - **Purpose**: Useful for extracting meaningful information from text and organizing it into predefined categories.\n",
    "\n",
    "### 8. **Normalization**\n",
    "   - **Definition**: This includes processes such as removing punctuation, special characters, and correcting typos.\n",
    "   - **Purpose**: Ensures a consistent format for text data, improving the quality of analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize # Tokenizer\n",
    "from nltk.corpus import stopwords # Stopwords removal\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer # Stemming and Lemmatizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Last summer, Alice and Bob traveled to Paris. They enjoyed running along the Seine and admired the beautiful buildings.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer \n",
    "- Sentence Tokenizer\n",
    "- Word Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Tokens: \n",
      " ['Last summer, Alice and Bob traveled to Paris.', 'They enjoyed running along the Seine and admired the beautiful buildings.']\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence Tokens: \\n\", nltk.sent_tokenize(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Tokens: \n",
      " ['Last', 'summer', ',', 'Alice', 'and', 'Bob', 'traveled', 'to', 'Paris', '.', 'They', 'enjoyed', 'running', 'along', 'the', 'Seine', 'and', 'admired', 'the', 'beautiful', 'buildings', '.']\n"
     ]
    }
   ],
   "source": [
    "words = nltk.word_tokenize(text)\n",
    "print(\"Word Tokens: \\n\", words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['last', 'summer', ',', 'alice', 'and', 'bob', 'traveled', 'to', 'paris', '.', 'they', 'enjoyed', 'running', 'along', 'the', 'seine', 'and', 'admired', 'the', 'beautiful', 'buildings', '.']\n"
     ]
    }
   ],
   "source": [
    "words = [word.lower() for word in words]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179 i\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "print(len(stop_words), stop_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['last', 'summer', ',', 'alice', 'bob', 'traveled', 'paris', '.', 'enjoyed', 'running', 'along', 'seine', 'admired', 'beautiful', 'buildings', '.']\n"
     ]
    }
   ],
   "source": [
    "words_filtered = [word for word in words if word not in stop_words]\n",
    "print(words_filtered) # stop words removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['last', 'summer', ',', 'alic', 'bob', 'travel', 'pari', '.', 'enjoy', 'run', 'along', 'sein', 'admir', 'beauti', 'build', '.']\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stem_words = [stemmer.stem(word) for word in words_filtered]\n",
    "print(stem_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['last', 'summer', ',', 'alice', 'bob', 'traveled', 'paris', '.', 'enjoyed', 'running', 'along', 'seine', 'admired', 'beautiful', 'building', '.']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words_filtered]\n",
    "print(lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('last', 'JJ'), ('summer', 'NN'), (',', ','), ('alice', 'NN'), ('bob', 'NN'), ('traveled', 'VBD'), ('paris', 'NN'), ('.', '.'), ('enjoyed', 'VBN'), ('running', 'VBG'), ('along', 'RB'), ('seine', 'NN'), ('admired', 'VBD'), ('beautiful', 'JJ'), ('buildings', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "pos_tags = nltk.pos_tag(words_filtered)\n",
    "print(pos_tags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
